			+--------------------+
			|       CS 4284      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

Kevin Pike <kpike90@vt.edu>
Ollie Harlowe <oharlowe@vt.edu>
Mike O'Beirne <mobeirne@vt.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

  N/A

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

No additional sources consulted.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct sleep_block - Holds the thread, start time, and list_elem of a
                     thread thtat's put to sleep. Allows us to keep track
                     of threads we've blocked who are 'asleep'.

static struct list sleep_queue - This queue held all of the sleeping threads. 
                                 Allowed us to block sleeping threads
                                 and wake them later. List consisted of 
                                 sleep_block structs.


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

A sleep_block is constructed holding the start time, length, and thread
to be slept. Then if the time to sleep is a valid one (that is, the
number of ticks to sleep hasn't already been done) we disable interrupts
(to guarantee exclusivity on the list) and push the block we created on
to the back of the sleep_queue. Then we block the thread and re-enable
interrupts.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

With regard to the alarm clock capabilities, not a ton could be done
to minimize the time. We simply iterated through the sleep queue to 
see if any threads should be woken, unblocking them if necessary.

With regard to necessary tasks for the advanced scheduler, we applied
the following optimizations:
 - Only updated the current thread's priority every 4 ticks
 - Only performed mlfqs options if mlfqs was enabled, so as not
   to slow down the basic scheduling if mlfqs wasn't turned on
 - Only updated highest_priority if it has changed
 - Only yield_on_return if the highest_priority has changed

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

When any thread goes to edit the sleep_queue, we make sure to turn off
interrupts. It's safe for each thread to prepare the sleep_block 
concurrently, but when one goes to use the list, we made it thread safe
through turning off interrupts.

Since we don't have multiple CPUs running, we don't need to worry
about simultaneous access outside of timer interrupts.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

The only time a timer interrupt can be called (because we turn it off
otherwise) is when the sleep_block is being constructed. This part
of timer_sleep() is thread safe and can be done concurrently.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

This design was particularly simple and proved to be fast enough. 
We considered a design of somehow keeping track of the "next wake
up" time, but that would prove to be a bit more complicated and
would likely be marginally more efficient at best.

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In thread.c,
	static struct list ready_list[64];
		Each priority gets a list to store ready threads.
	static int highest_priority;
		The highest priority in the ready list. It is used to properly yield threads
		when they exceed or drop below it.
	static struct list donation_list;
		List of all the threads that have had priority donated to them. It is used 
		to implement priority chain donation.

In thread.h
Additions to struct thread:
	int old_priority
		When a thread recieves priority donation, the original priority before 
		donation is stored in old_priority.
	struct list donation_locks
		A list of locks that have donated to the thread. This is used for priority 
		donation. 
	struct list_elem donation_elem
		A list_elem to insert the thread into the donation_list of thread.c

In synch.h
Additions to struct lock:
	int list_elem elem
		List element so locks can be inserted into a threads list of donation locks.
	bool donation
		Whether or not a lock has caused a donation. It is used as quick check to 
		see if a donation needs to be returned in lock_release.
>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

The data structure used to track priority donation is list of threads that hold 
a lock that earned the thread a donation called the donation list. A thread is 
added to the donation list when it is donated to and it is removed when no other
 threads need to donate to it. Since the locks already have a list of waiters, 
the locks are used to iterate over it's waiters and choose what waiter will 
donate to the thread in the case of the initial thread being removed from the 
lock's waiters. Priority is donated in a nested fashion because when a thread 
receives a donation, it iterates the donation list to check the thread's locks 
to see if it is a waiter. If it is, it will pass on the donation to the 
lock holder. 

Donation List:
	Key:
	| = list connection
	A -> 1: B A holds lock 1 of which B is a waiter

L -> 1: M
|
M -> 2: H

When H donates to M, L's lock 1's waiters will be checked for M.

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

In order to ensure that the highest priority thread wakes up first 
when a semaphore is incremented (sema_up), the waiting list 
(waiters) is iterated over. If the thread in the list has a higher
priority than the current highest priority thread (which is set
as the first thread in the list before the loop), then the pointer
to the current thread with the highest priority is set to the 
higher priority thread. Therefore, the pointer to the thread that 
will be unblocked always points to the highest priority thread in 
the waiting list. Locks are implemented with semaphores, so they 
call sema_up to release in which case the above algorithm applies 
to them as well. Condition variables iterate over the list of
condition waiters and compares the waiting thread in each 
semaphore's list of waiters to the current thread with the highest 
priority. The thread with the higher of the two priorities is 
taken. Therefore, the thread with the highest priority is woken up 
and removed from the condition waiters list.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
	
First, when lock_acquire is called there is a check to make sure 
there is a lock holder and to see if the lock holder's priority is 
less than the current thread trying to acquire the lock. If both 
conditions are true then the method donate_priority_to is called
and is passed the lock. In donate_priority_to the list of threads
that have been donated to is iterated over. If the lock holder is
found in the list then every lock that every thread in the list of
donated threads is iterated over. If the lock holder is found in
any of the waiting lists for any lock held by a donated thread then
that lock's holder is given the priority of the current thread 
trying to acquire the lock. Nested donation is handled by looping
this algorithm until a thread is found that is not blocked, 
therefore not waiting on a lock. Additionally, if a thread is not 
found in the donated thread list then it is added to the list.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

In lock_release, if the lock holder has already been donated to
then the new priority of the lock holder is set by calling the
method return_priority which is passed the lock. In 
return_priority, if the lock holder still has locks that have
caused a donation, then the list of those locks and the lists of
those threads waiting on those locks (waiters) are iterated over.
While iterating, if the current thread in the list has a higher
priority than the current thread with the highest priority, then
the higher priority is saved as the current highest priority. In
this way, every thread that is waiting on the thread that is about
to release the lock is looked at to see which has the highest 
priority and the lock holder is given that priority.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

A potential race condition in our thread_set_priority is that when two 
threads call thread_set_priority at the same time and are preempted properly
so that they simultaneously. This would happen because high_priority is 
calculated in the case where new_priority is lower than the global 
highest_priority. The value can be improperly set if both threads access
the ready list at the same time. This race can be avoided by locking access
to the ready list so that only one thread will be able to access the ready
list at one time. 

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design because we wanted to utilize the list of waiters in 
the lock's semaphore and figured that the lists wouldn't get too long so 
iterating over all donated threads, locks, and waiters wouldn't cause a 
problem. It is superior to two designs we considered. We considered making a
list of a struct that held the thread that received a donation, it's lock, 
and the list of waiters for the lock. The lock already has the waiters so this
was redundant. Also, we thought about just keeping a list of locks. This would
cause a problem when a thread holds multiple locks and has it's priority
returned. In this case with a list of locks, the entire list would have to be 
iterated. By keeping a list of locks in thread, the locks can be quickly
accessed. 

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

fixed_point_t - a structure to represent a fixed point integer. Was
                really just a wrapper for an integer, but made
                the compiler check for correct use.

struct thread
        - Added mlfqs members 'nice' and 'recent_cpu' to track the
          thread's values.

static int ready_threads - Kept track of the number of threads
                           in the running or ready state. Used for
                           mlfqs calculations.

fixed_point_t load_avg - Used for mlfqs calculations. Was a moving average
                         of the number of ready threads.


---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0      0   0   0  63  61  59     A
 4      4   0   0  62  61  59     A
 8      8   0   0  61  61  59     B
12      8   4   0  61  60  59     A
16     12   4   0  60  60  59     B
20     12   8   0  60  59  59     A
24     16   8   0  59  59  59     C
28     16   8   4  59  59  58     B
32     16   12  4  59  58  58     A
36     20   12  4  58  58  58     B

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

The only thing I think that could be up to interpretation would be
as how to define "round robin". One could do it FIFO or LIFO. We did
ours FIFO, hence the behavior in the table above.

I've clearly assumed above that 36 timer ticks is less than a second
to drasticly simplify the table and calculations that went into it.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

If there's too much to do in an interrupt context, threads could be
"cheated" out of their run-time. Also, the load_avg value will 
change because of the timing of when it is calculated. 

We also want to minimize the amount done in the interrupt context because
in a lot of it, interrupts are turned off. This can cause latency issues,
which we strongly wish to avoid.


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

Our design actually worked out pretty well. The Priority donation
scheduler and the Advanced scheduler existed almost independently,
so work could be done simultaneously on them. There were about 
3-4 changes that needed to be made after merging the code, but
that's relatively cheap considering how much work/change went into
both.

If I had extra time to work on the project, I would want to improve
the efficiency of the code, especially in the interrupt context. I
would also attempt to clean up some of the code so as to allow
multiple choices in scheduling options very easily. This would
allow testing with different schedulers to be done very effortlessly.


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

I decided to implement the fixed_point_t struct to force the compiler
to throw errors if we ever treated it like an int or it was confused
as one. This wrapper made working with the fixed_point numbers much
safer and I had no issues with them.

The functions were made instead of #define macros because errors with
them would be much simpler to debug than macros that are just inlined.

In general, we tried to make the compiler catch as many errors as
possible.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

  I believe this assignment was a bit hard, but a good first assignment.
  We'll see how hard the other ones are, but I'd say it's a good intro 
  to kernel development. 

  Having the testing given to us makes things completely more manageable.

  It took a pretty fair amount of time.

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

  Working with this project helped completely reshape our understanding
  of interrupts, and the work done in an interrupt context. Also, the
  amount of optimization that needs to occur when working on kernals,
  and the effect of said optimization.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

  An introduction or some required reading on version control would be
  useful for the future. An emphasis that the Advanced Scheduler may
  fail tests due to too much time spent in the interrupt context wouldn't
  hurt, though that was definitely mentioned.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?
  
  I can't think of any way to really make this easier. The assignment
  was really fair, in my opinion.

>> Any other comments?

  Pretty fun project, and we're excited for the next one.
